---
title: 'lime v0.4: The kitten picture edition'
description: "The new version of lime adds support for image models as well as build-in support for keras models and range of other tweaks"
author: "Thomas Lin Pedersen"
date: '2018-03-06'
output: pdf_document
large_thumb: yes
img:
  thumb: /assets/images/kitten_lime.png
slug: lime-v0-4-the-kitten-picture-edition
tags:
- announcement
- lime
- machine learning
- prediction
- modelling
categories: 
- R
---



<p><img src="/assets/images/lime_logo_small.jpg" align="right" style="width:50%"/></p>
<p>I’m happy to report a new major release of <code>lime</code> has landed on CRAN. <code>lime</code> is an R port of the Python library of the same name by Marco Ribeiro that allows the user to pry open black box machine learning models and explain their outcomes on a per-observation basis. It works by modelling the outcome of the black box in the local neighborhood around the observation to explain and using this local model to explain why (not how) the black box did what it did. For more information about the theory of <code>lime</code> I will direct you to the article <a href="https://arxiv.org/abs/1602.04938">introducing the methodology</a>.</p>
<div id="new-features" class="section level2">
<h2>New features</h2>
<p>The meat of this release centers around two new features that are somewhat linked: Native support for keras models and support for explaining image models.</p>
<div id="keras-and-images" class="section level3">
<h3>keras and images</h3>
<p>J.J. Allaire was kind enough to namedrop <code>lime</code> during his keynote introduction of the <code>tensorflow</code> and <code>keras</code> packages and I felt compelled to support them natively. As keras is by far the most popular way to interface with tensorflow it is first in line for build-in support. The addition of keras means that <code>lime</code> now directly supports models from the following packages:</p>
<ul>
<li><a href="https://github.com/topepo/caret">caret</a></li>
<li><a href="https://github.com/mlr-org/mlr">mlr</a></li>
<li><a href="https://github.com/dmlc/xgboost">xgboost</a></li>
<li><a href="https://github.com/h2oai/h2o-3">h2o</a></li>
<li><a href="https://github.com/rstudio/keras">keras</a></li>
</ul>
<p>If you’re working on something too obscure or cutting edge to not be able to use these packages it is still possible to make your model <code>lime</code> compliant by providing <code>predict_model()</code> and <code>model_type()</code> methods for it.</p>
<p>keras models are used just like any other model, by passing it into the <code>lime()</code> function along with the training data in order to create an explainer object. Because we’re soon going to talk about image models, we’ll be using one of the pre-trained ImageNet models that is available from keras itself:</p>
<pre class="r"><code>library(keras)
library(lime)
library(magick)

model &lt;- application_vgg16(
  weights = &quot;imagenet&quot;,
  include_top = TRUE
)
model</code></pre>
<pre><code>## Model
## ___________________________________________________________________________
## Layer (type)                     Output Shape                  Param #     
## ===========================================================================
## input_1 (InputLayer)             (None, 224, 224, 3)           0           
## ___________________________________________________________________________
## block1_conv1 (Conv2D)            (None, 224, 224, 64)          1792        
## ___________________________________________________________________________
## block1_conv2 (Conv2D)            (None, 224, 224, 64)          36928       
## ___________________________________________________________________________
## block1_pool (MaxPooling2D)       (None, 112, 112, 64)          0           
## ___________________________________________________________________________
## block2_conv1 (Conv2D)            (None, 112, 112, 128)         73856       
## ___________________________________________________________________________
## block2_conv2 (Conv2D)            (None, 112, 112, 128)         147584      
## ___________________________________________________________________________
## block2_pool (MaxPooling2D)       (None, 56, 56, 128)           0           
## ___________________________________________________________________________
## block3_conv1 (Conv2D)            (None, 56, 56, 256)           295168      
## ___________________________________________________________________________
## block3_conv2 (Conv2D)            (None, 56, 56, 256)           590080      
## ___________________________________________________________________________
## block3_conv3 (Conv2D)            (None, 56, 56, 256)           590080      
## ___________________________________________________________________________
## block3_pool (MaxPooling2D)       (None, 28, 28, 256)           0           
## ___________________________________________________________________________
## block4_conv1 (Conv2D)            (None, 28, 28, 512)           1180160     
## ___________________________________________________________________________
## block4_conv2 (Conv2D)            (None, 28, 28, 512)           2359808     
## ___________________________________________________________________________
## block4_conv3 (Conv2D)            (None, 28, 28, 512)           2359808     
## ___________________________________________________________________________
## block4_pool (MaxPooling2D)       (None, 14, 14, 512)           0           
## ___________________________________________________________________________
## block5_conv1 (Conv2D)            (None, 14, 14, 512)           2359808     
## ___________________________________________________________________________
## block5_conv2 (Conv2D)            (None, 14, 14, 512)           2359808     
## ___________________________________________________________________________
## block5_conv3 (Conv2D)            (None, 14, 14, 512)           2359808     
## ___________________________________________________________________________
## block5_pool (MaxPooling2D)       (None, 7, 7, 512)             0           
## ___________________________________________________________________________
## flatten (Flatten)                (None, 25088)                 0           
## ___________________________________________________________________________
## fc1 (Dense)                      (None, 4096)                  102764544   
## ___________________________________________________________________________
## fc2 (Dense)                      (None, 4096)                  16781312    
## ___________________________________________________________________________
## predictions (Dense)              (None, 1000)                  4097000     
## ===========================================================================
## Total params: 138,357,544
## Trainable params: 138,357,544
## Non-trainable params: 0
## ___________________________________________________________________________</code></pre>
<p>The vgg16 model is an image classification model that has been build as part of the ImageNet competition where the goal is to classify pictures into 1000 categories with the highest accuracy. As we can see it is fairly complicated.</p>
<p>In order to create an explainer we will need to pass in the training data as well. For image data the training data is really only used to tell lime that we are dealing with an image model, so any image will suffice. The format for the training data is simply the path to the images, and because the internet runs on kitten pictures we’ll use one of these:</p>
<pre class="r"><code>img &lt;- image_read(&#39;https://www.data-imaginist.com/assets/images/kitten.jpg&#39;)
img_path &lt;- file.path(tempdir(), &#39;kitten.jpg&#39;)
image_write(img, img_path)
plot(as.raster(img))</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-2"></span>
<img src="/post/2018-03-06-lime-v0-4-the-kitten-picture-edition_files/figure-html/unnamed-chunk-2-1.png" alt="Photo by Paul on Unsplash" width="672" />
<p class="caption">
Figure 1: Photo by Paul on Unsplash
</p>
</div>
<p>As with text models the explainer will need to know how to prepare the input data for the model. For keras models this means formatting the image data as tensors. Thankfully keras comes with a lot of tools for reshaping image data:</p>
<pre class="r"><code>image_prep &lt;- function(x) {
  arrays &lt;- lapply(x, function(path) {
    img &lt;- image_load(path, target_size = c(224,224))
    x &lt;- image_to_array(img)
    x &lt;- array_reshape(x, c(1, dim(x)))
    x &lt;- imagenet_preprocess_input(x)
  })
  do.call(abind::abind, c(arrays, list(along = 1)))
}
explainer &lt;- lime(img_path, model, image_prep)</code></pre>
<p>We now have an explainer model for understanding how the vgg16 neural network makes its predictions. Before we go along, lets see what the model think of our kitten:</p>
<pre class="r"><code>res &lt;- predict(model, image_prep(img_path))
imagenet_decode_predictions(res)</code></pre>
<pre><code>## [[1]]
##   class_name class_description      score
## 1  n02124075      Egyptian_cat 0.48913878
## 2  n02123045             tabby 0.15177219
## 3  n02123159         tiger_cat 0.10270492
## 4  n02127052              lynx 0.02638111
## 5  n03793489             mouse 0.00852214</code></pre>
<p>So, it is pretty sure about the whole cat thing. The reason we need to use <code>imagenet_decode_predictions()</code> is that the output of a keras model is always just a nameless tensor:</p>
<pre class="r"><code>dim(res)</code></pre>
<pre><code>## [1]    1 1000</code></pre>
<pre class="r"><code>dimnames(res)</code></pre>
<pre><code>## NULL</code></pre>
<p>We are used to classifiers knowing the class labels, but this is not the case for keras. Motivated by this, <code>lime</code> now have a way to define/overwrite the class labels of a model, using the <code>as_classifier()</code> function. Let’s redo our explainer:</p>
<pre class="r"><code>model_labels &lt;- readRDS(system.file(&#39;extdata&#39;, &#39;imagenet_labels.rds&#39;, package = &#39;lime&#39;))
explainer &lt;- lime(img_path, as_classifier(model, model_labels), image_prep)</code></pre>
<blockquote>
<p>There is also an <code>as_regressor()</code> function which tells <code>lime</code>, without a doubt, that the model is a regression model. Most models can be introspected to see which type of model they are, but neural networks doesn’t really care. <code>lime</code> guesses the model type from the activation used in the last layer (linear activation == regression), but if that heuristic fails then <code>as_regressor()</code>/<code>as_classifier()</code> can be used.</p>
</blockquote>
<p>We are now ready to poke into the model and find out what makes it think our image is of an Egyptian cat. But… first I’ll have to talk about yet another concept: superpixels (I promise I’ll get to the explanation part in a bit).</p>
<p>In order to create meaningful permutations of our image (remember, this is the central idea in <code>lime</code>), we have to define how to do so. The permutations needs to be substantial enough to have an impact on the image, but not so much that the model completely fails to recognise the content in every case - further, they should lead to an interpretable result. The concept of superpixels lends itself well to these constraints. In short, a superpixel is a patch of an area with high homogeneity, and superpixel segmentation is a clustering of image pixels into a number of superpixels. By segmenting the image to explain into superpixels we can turn area of contextual similarity on and off during the permutations and find out if that area is important. It is still necessary to experiment a bit as the optimal number of superpixels depend on the content of the image. Remember, we need them to be large enough to have an impact but not so large that the class probability becomes effectively binary. <code>lime</code> comes with a function to assess the superpixel segmentation before beginning the explanation and it is recommended to play with it a bit — with time you’ll likely get a feel for the right values:</p>
<pre class="r"><code># default
plot_superpixels(img_path)</code></pre>
<p><img src="/post/2018-03-06-lime-v0-4-the-kitten-picture-edition_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code># Changing some settings
plot_superpixels(img_path, n_superpixels = 200, weight = 40)</code></pre>
<p><img src="/post/2018-03-06-lime-v0-4-the-kitten-picture-edition_files/figure-html/unnamed-chunk-7-2.png" width="672" /></p>
<p>The default is set to a pretty low number of superpixels — if the subject of interest is relatively small it may be necessary to increase the number of superpixels so that the full subject does not end up in one, or a few superpixels. The <code>weight</code> parameter will allow you to make the segments more compact by weighting spatial distance higher than colour distance. For this example we’ll stick with the defaults.</p>
<p>Be aware that explaining image models is much heavier than tabular or text data. In effect it will create 1000 new images per explanation (default permutation size for images) and run these through the model. As image classification models are often quite heavy, this will result in computation time measured in minutes. The permutation is batched (default to 10 permutations per batch), so you should not be afraid of running out of RAM or hard-drive space.</p>
<pre class="r"><code>explanation &lt;- explain(img_path, explainer, n_labels = 2, n_features = 20)</code></pre>
<p>The output of an image explanation is a data frame of the same format as that from tabular and text data. Each feature will be a superpixel and the pixel range of the superpixel will be used as its description. Usually the explanation will only make sense in the context of the image itself, so the new version of <code>lime</code> also comes with a <code>plot_image_explanation()</code> function to do just that. Let’s see what our explanation have to tell us:</p>
<pre class="r"><code>plot_image_explanation(explanation)</code></pre>
<p><img src="/post/2018-03-06-lime-v0-4-the-kitten-picture-edition_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>We can see that the model, for both the major predicted classes, focuses on the cat, which is nice since they are both different cat breeds. The plot function got a few different functions to help you tweak the visual, and it filters low scoring superpixels away by default. An alternative view that puts more focus on the relevant superpixels, but removes the context can be seen by using <code>display = 'block'</code>:</p>
<pre class="r"><code>plot_image_explanation(explanation, display = &#39;block&#39;, threshold = 0.01)</code></pre>
<p><img src="/post/2018-03-06-lime-v0-4-the-kitten-picture-edition_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>While not as common with image explanations it is also possible to look at the areas of an image that contradicts the class:</p>
<pre class="r"><code>plot_image_explanation(explanation, threshold = 0, show_negative = TRUE, fill_alpha = 0.6)</code></pre>
<p><img src="/post/2018-03-06-lime-v0-4-the-kitten-picture-edition_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>As each explanation takes longer time to create and needs to be tweaked on a per-image basis, image explanations are not something that you’ll create in large batches as you might do with tabular and text data. Still, a few explanations might allow you to understand your model better and be used for communicating the workings of your model. Further, as the time-limiting factor in image explanations are the image classifier and not lime itself, it is bound to improve as image classifiers becomes more performant.</p>
</div>
<div id="grab-back" class="section level3">
<h3>Grab back</h3>
<p>Apart from keras and image support, a slew of other features and improvements have been added. Here’s a quick overview:</p>
<ul>
<li>All explanation plots now include the fit of the ridge regression used to make the explanation. This makes it easy to assess how good the assumptions about local linearity are kept.</li>
<li>When explaining tabular data the default distance measure is now <code>'gower'</code> from the <code>gower</code> package. <code>gower</code> makes it possible to measure distances between heterogeneous data without converting all features to numeric and experimenting with different exponential kernels.</li>
<li>When explaining tabular data numerical features will no longer be sampled from a normal distribution during permutations, but from a kernel density defined by the training data. This should ensure that the permutations are more representative of the expected input.</li>
</ul>
</div>
</div>
<div id="wrapping-up" class="section level2">
<h2>Wrapping up</h2>
<p>This release represents an important milestone for <code>lime</code> in R. With the addition of image explanations the <code>lime</code> package is now on par or above its Python relative, feature-wise. Further development will focus on improving the performance of the model, e.g. by adding parallelisation or improving the local model definition, as well as exploring alternative explanation types such as <a href="https://homes.cs.washington.edu/%7Emarcotcr/aaai18.pdf">anchor</a>.</p>
<p>Happy Explaining!</p>
</div>
